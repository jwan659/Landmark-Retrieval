{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Code Adapted from the following sources\n### https://www.kaggle.com/camaskew/host-baseline-example?scriptVersionId=40287695 \n### https://github.com/dvschultz/ml-art-colabs/blob/master/ML4A_image_search.ipynb ###\nimport gc\nimport os\nimport PIL\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow.keras as keras\nimport tensorflow as tf\n\nfrom scipy import spatial\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\nfrom tqdm.notebook import tqdm\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import decode_predictions, preprocess_input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-02T15:41:59.882198Z","iopub.execute_input":"2021-09-02T15:41:59.882585Z","iopub.status.idle":"2021-09-02T15:42:04.460628Z","shell.execute_reply.started":"2021-09-02T15:41:59.882501Z","shell.execute_reply":"2021-09-02T15:42:04.459789Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = os.path.join('..', 'input')\nDATASET_DIR = os.path.join(INPUT_DIR, 'landmark-retrieval-2021')\nTEST_IMAGE_DIR = os.path.join(DATASET_DIR, 'test')\nTRAIN_IMAGE_DIR = os.path.join(DATASET_DIR, 'train')\nINDEX_IMAGE_DIR = os.path.join(DATASET_DIR, 'index')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:42:04.462070Z","iopub.execute_input":"2021-09-02T15:42:04.462428Z","iopub.status.idle":"2021-09-02T15:42:04.466818Z","shell.execute_reply.started":"2021-09-02T15:42:04.462392Z","shell.execute_reply":"2021-09-02T15:42:04.466024Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def load_image(path):\n    \"\"\"Returns PIL and ndarray format of image based on path given.\"\"\"\n    img = image.load_img(path, target_size=model.input_shape[1:3])\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    return img, x","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:42:04.468699Z","iopub.execute_input":"2021-09-02T15:42:04.469192Z","iopub.status.idle":"2021-09-02T15:42:04.480826Z","shell.execute_reply.started":"2021-09-02T15:42:04.469155Z","shell.execute_reply":"2021-09-02T15:42:04.480000Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Let's load all the index images and store them in a list.","metadata":{}},{"cell_type":"code","source":"image_extensions = ['.jpg', '.png', '.jpeg']   # case-insensitive (upper/lower doesn't matter)\nindex_images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(INDEX_IMAGE_DIR) for f in filenames if os.path.splitext(f)[1].lower() in image_extensions]\nprint(\"keeping %d images to analyze\" % len(index_images))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:42:04.483882Z","iopub.execute_input":"2021-09-02T15:42:04.484206Z","iopub.status.idle":"2021-09-02T15:42:22.751527Z","shell.execute_reply.started":"2021-09-02T15:42:04.484171Z","shell.execute_reply":"2021-09-02T15:42:22.749514Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"keeping 76176 images to analyze\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next we'll load our model and remove the classification layer. For more info see: https://github.com/dvschultz/ml-art-colabs/blob/master/ML4A_image_search.ipynb","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nmodel = VGG16(weights='../input/tf-keras-pretrained-model-weights/Top/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\nfeat_extractor = Model(inputs=model.input, outputs=model.get_layer(\"fc2\").output)\nfeat_extractor.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:42:22.753612Z","iopub.execute_input":"2021-09-02T15:42:22.753857Z","iopub.status.idle":"2021-09-02T15:42:32.619097Z","shell.execute_reply.started":"2021-09-02T15:42:22.753833Z","shell.execute_reply":"2021-09-02T15:42:32.618156Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n=================================================================\nTotal params: 134,260,544\nTrainable params: 134,260,544\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After that let's extract the features of each image in the index list and store it in a list. For the dataset of ~76k images, this should take around an hour using Kaggle's GPU. We'll also grab the IDs of each image in a separate list.","metadata":{}},{"cell_type":"code","source":"features = []\nids = []\nfor i, image_path in enumerate(tqdm(index_images)):\n    img, x = load_image(image_path);\n    feat = feat_extractor.predict(x)[0]\n    features.append(feat)\n    ids.append(image_path.split('/')[-1][:-4])\n\nprint('finished extracting features for %d images' % len(index_images))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:42:32.621285Z","iopub.execute_input":"2021-09-02T15:42:32.621648Z","iopub.status.idle":"2021-09-02T16:47:42.275386Z","shell.execute_reply.started":"2021-09-02T15:42:32.621611Z","shell.execute_reply":"2021-09-02T16:47:42.274433Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/76176 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9490e09e7f934deabd6a27f74f279788"}},"metadata":{}},{"name":"stdout","text":"finished extracting features for 76176 images\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Apply PCA to reduce the dimensionality of the image features, keeping top 300 principal components.","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport numpy as np\nfeatures = np.array(features)\npca = PCA(n_components=300)\npca.fit(features)\npca_features = pca.transform(features)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T16:47:42.276823Z","iopub.execute_input":"2021-09-02T16:47:42.277187Z","iopub.status.idle":"2021-09-02T16:48:21.406241Z","shell.execute_reply.started":"2021-09-02T16:47:42.277149Z","shell.execute_reply":"2021-09-02T16:48:21.405189Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"The next function wwas grabbed from DV Schultz's notebook and returns the closest images based on a given distance threshold.","metadata":{}},{"cell_type":"code","source":"from scipy.spatial import distance\n# function to return the largest and closest looking images from the index set\ndef get_closest_images(test_feat, threshold=0.2):\n    distances = [distance.cosine(test_feat, feat) for feat in pca_features]\n    dct = {i: distances[i] for i in range(0, len(distances), 1)}\n    sorted_dict = dict(sorted(dct.items(), key=lambda item: item[1]))\n    valid_dict = {key:val for key, val in sorted_dict.items() if val < threshold}\n    idx_closest = valid_dict.keys()\n    dis_closest = list(valid_dict.values())\n    return idx_closest, dis_closest","metadata":{"execution":{"iopub.status.busy":"2021-09-02T16:48:21.408725Z","iopub.execute_input":"2021-09-02T16:48:21.409299Z","iopub.status.idle":"2021-09-02T16:48:21.418308Z","shell.execute_reply.started":"2021-09-02T16:48:21.409260Z","shell.execute_reply":"2021-09-02T16:48:21.417439Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_paths = []\noutput = pd.DataFrame(columns = ['id','images'])\nfor root, dirs, files in os.walk(os.path.join(TEST_IMAGE_DIR)):\n    for file in files:\n        if file.endswith('.jpg'):\n            test_paths.append(os.path.join(root, file))","metadata":{"execution":{"iopub.status.busy":"2021-09-02T16:48:21.419930Z","iopub.execute_input":"2021-09-02T16:48:21.420507Z","iopub.status.idle":"2021-09-02T16:48:23.628906Z","shell.execute_reply.started":"2021-09-02T16:48:21.420468Z","shell.execute_reply":"2021-09-02T16:48:23.628032Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i, path in enumerate(tqdm(test_paths)):\n    img, x  = load_image(path)\n    test_id = path.split('/')[-1][:-4]\n    test_feat = feat_extractor.predict(x)[0].reshape(1,-1)\n    test_pca = pca.transform(test_feat)\n    idx_closest, dis_closest = get_closest_images(test_pca)\n    index_id = []\n    for idx in idx_closest:\n        index_id.append(ids[idx])\n    index_ids = ' '.join(index_id)\n    output.loc[i] = [test_id, index_ids]\n    output.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T16:48:23.630345Z","iopub.execute_input":"2021-09-02T16:48:23.630692Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6053a2d59f8a47d0ad2a3b12be928641"}},"metadata":{}}]}]}